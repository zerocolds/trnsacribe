# --- Stage 1: whisper.cpp builder ---
FROM nvidia/cuda:12.2.0-base-ubuntu22.04 AS whisper-builder
ENV DEBIAN_FRONTEND=noninteractive
RUN apt-get update && apt-get install -y --no-install-recommends \
    git build-essential make cmake ninja-build ca-certificates \
 && rm -rf /var/lib/apt/lists/*
RUN git clone --depth 1 https://github.com/ggerganov/whisper.cpp.git /tmp/whisper.cpp \
 && cd /tmp/whisper.cpp \
 && make -j \
 && mkdir -p /opt/whisper \
 && if [ -f ./main ]; then \
        cp ./main /opt/whisper/whisper-cli; \
    elif [ -f ./build/bin/whisper-cli ]; then \
        cp ./build/bin/whisper-cli /opt/whisper/whisper-cli; \
    else \
        echo "whisper binary not found"; exit 1; \
    fi \
 && chmod +x /opt/whisper/whisper-cli

# --- Stage 2: final image ---
FROM nvidia/cuda:12.2.0-base-ubuntu22.04 AS runtime
ENV DEBIAN_FRONTEND=noninteractive
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-pip ffmpeg curl ca-certificates \
 && rm -rf /var/lib/apt/lists/*

RUN python3 -m pip install --upgrade pip \
 && pip install vllm requests srt pyannote.audio torch fastapi uvicorn

# Ollama (опционально)
RUN curl -fsSL https://ollama.com/install.sh | sh || true

# Кладём бинарь в PATH
COPY --from=whisper-builder /opt/whisper/whisper-cli /usr/local/bin/whisper-cli

WORKDIR /workspace
COPY ./localtrans .

EXPOSE 8080
CMD ["uvicorn", "localtrans.api_server:app", "--host", "0.0.0.0", "--port", "8080"]
